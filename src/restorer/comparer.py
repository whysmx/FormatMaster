"""
Format comparison module for Word documents.

This module provides functionality to compare XML structures between Word documents
to verify formatting restoration accuracy.
"""

import os
import tempfile
import zipfile
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from lxml import etree
from difflib import SequenceMatcher


class FormatComparer:
    """
    Compares formatting between Word documents.

    This class extracts and compares XML files from two Word documents
    to verify if formatting has been correctly restored.
    """

    # Non-deterministic attributes to ignore during comparison
    IGNORE_ATTRS = {
        "{http://schemas.openxmlformats.org/wordprocessingml/2006/main}rsidR",
        "{http://schemas.openxmlformats.org/wordprocessingml/2006/main}rsidRPr",
        "{http://schemas.openxmlformats.org/wordprocessingml/2006/main}rsidP",
        "{http://schemas.openxmlformats.org/wordprocessingml/2006/main}rsidDel",
        "{http://schemas.openxmlformats.org/wordprocessingml/2006/main}rsidRDefault",
        "{http://schemas.openxmlformats.org/wordprocessingml/2006/main}rsidSect",
        "{http://schemas.openxmlformats.org/wordprocessingml/2006/main}rsid",
        # Table row rsid (non-deterministic)
        "{http://schemas.openxmlformats.org/wordprocessingml/2006/main}rsidTr",
        # Word 2010+ non-deterministic attributes (auto-generated IDs)
        "{http://schemas.microsoft.com/office/word/2010/wordml}paraId",
        "{http://schemas.microsoft.com/office/word/2010/wordml}textId",
        # Word 2010+ drawing non-deterministic attributes (auto-generated IDs for images/shapes)
        "{http://schemas.microsoft.com/office/word/2010/wordprocessingDrawing}anchorId",
        "{http://schemas.microsoft.com/office/word/2010/wordprocessingDrawing}editId",
        # Relationship embed IDs (vary between documents but don't affect visual appearance)
        "{http://schemas.openxmlformats.org/officeDocument/2006/relationships}embed",
        "{http://schemas.openxmlformats.org/officeDocument/2006/relationships}link",
        # XML space preservation attribute (often varies between documents)
        "{http://www.w3.org/XML/1998/namespace}space",
        # Metadata timestamps
        "{http://schemas.openxmlformats.org/package/2006/metadata/core-properties}lastModifiedBy",
        "{http://purl.org/dc/elements/1.1/}modified",
        "{http://purl.org/dc/elements/1.1/}created",
        "{http://schemas.openxmlformats.org/package/2006/metadata/core-properties}revision",
    }

    # Non-deterministic elements to ignore during comparison
    # These are run-level formatting elements that don't affect the semantic structure
    IGNORE_ELEMENTS = {
        "{http://schemas.openxmlformats.org/wordprocessingml/2006/main}rPr",
        # Run properties (direct formatting like fonts, colors, bold, italic, etc.)
        # These are ignored because we want to compare document structure and content,
        # not direct formatting which may vary between documents with the same semantic meaning
        "{http://schemas.openxmlformats.org/wordprocessingml/2006/main}lastRenderedPageBreak",
        # Non-deterministic page break markers generated by Word
        "{http://schemas.openxmlformats.org/wordprocessingml/2006/main}proofErr",
        # Spelling/grammar error markers
        "{http://schemas.openxmlformats.org/wordprocessingml/2006/main}noProof",
        # Proofing skip markers
        "{http://schemas.openxmlformats.org/wordprocessingml/2006/main}bookmarkStart",
        # Bookmark start markers (navigation markers, don't affect visual appearance)
        "{http://schemas.openxmlformats.org/wordprocessingml/2006/main}bookmarkEnd",
        # Bookmark end markers (navigation markers, don't affect visual appearance)
        "{http://schemas.openxmlformats.org/wordprocessingml/2006/main}commentRangeStart",
        # Comment range start markers (comments don't affect main content)
        "{http://schemas.openxmlformats.org/wordprocessingml/2006/main}commentRangeEnd",
        # Comment range end markers (comments don't affect main content)
        "{http://schemas.openxmlformats.org/wordprocessingml/2006/main}commentReference",
        # Comment reference markers (comments don't affect main content)
    }

    # Content XML files that must be identical for formatting comparison
    CONTENT_XML_FILES = {
        "word/document.xml",
        "word/header1.xml",
        "word/header2.xml",
        "word/header3.xml",
        "word/footer1.xml",
        "word/footer2.xml",
        "word/footer3.xml",
        "word/footnotes.xml",
        "word/endnotes.xml",
        "word/comments.xml",
        "word/numbering.xml",
        "word/people.xml",
    }

    def __init__(self):
        """Initialize the FormatComparer."""
        pass

    def compare_documents(
        self,
        doc1_path: str,
        doc2_path: str,
        specific_file: Optional[str] = None,
        full_compare: bool = True,
    ) -> Dict:
        """
        Compare two Word documents and generate a comparison report.

        Args:
            doc1_path: Path to the first document (reference/standard)
            doc2_path: Path to the second document (to be verified)
            specific_file: Optional specific XML file to compare (e.g., 'styles.xml')
            full_compare: If True, compare all XML files; if False, only format files

        Returns:
            Dictionary containing comparison results
        """
        doc1_path = Path(doc1_path)
        doc2_path = Path(doc2_path)

        if not doc1_path.exists():
            raise FileNotFoundError(f"Document not found: {doc1_path}")
        if not doc2_path.exists():
            raise FileNotFoundError(f"Document not found: {doc2_path}")

        # Extract documents
        with tempfile.TemporaryDirectory() as temp_dir:
            doc1_dir = Path(temp_dir) / "doc1"
            doc2_dir = Path(temp_dir) / "doc2"
            doc1_dir.mkdir()
            doc2_dir.mkdir()

            self._extract_docx(doc1_path, doc1_dir)
            self._extract_docx(doc2_path, doc2_dir)

            # Check content consistency first
            content_consistent = self._check_content_consistency(doc1_dir, doc2_dir)

            # Compare XML files regardless of content consistency
            # This allows users to see format similarity even when content differs
            if specific_file:
                file_comparisons = {
                    specific_file: self._compare_xml_file(
                        doc1_dir / specific_file,
                        doc2_dir / specific_file
                    )
                }
            elif full_compare:
                # Compare all XML files
                file_comparisons = self._compare_all_xml_files(doc1_dir, doc2_dir)
            else:
                # Compare only format-related files
                file_comparisons = self._compare_format_files(doc1_dir, doc2_dir)

            # Calculate overall similarity
            overall_similarity = self._calculate_similarity(file_comparisons)

            return {
                "content_consistent": content_consistent,
                "file_comparisons": file_comparisons,
                "overall_similarity": overall_similarity,
            }

    def _extract_docx(self, docx_path: Path, extract_dir: Path) -> None:
        """Extract a .docx file to a directory."""
        with zipfile.ZipFile(docx_path, 'r') as zip_ref:
            zip_ref.extractall(extract_dir)

    def _check_content_consistency(self, dir1: Path, dir2: Path) -> bool:
        """
        Check if content XML files are consistent between documents.

        Args:
            dir1: Extracted directory of first document
            dir2: Extracted directory of second document

        Returns:
            True if content is consistent, False otherwise
        """
        for content_file in self.CONTENT_XML_FILES:
            file1 = dir1 / content_file
            file2 = dir2 / content_file

            # If both files exist, compare their text content
            if file1.exists() and file2.exists():
                try:
                    tree1 = etree.parse(file1)
                    tree2 = etree.parse(file2)

                    # Get all text from both documents
                    text1 = self._extract_all_text(tree1.getroot())
                    text2 = self._extract_all_text(tree2.getroot())

                    if text1 != text2:
                        return False
                except Exception:
                    # If parsing fails, assume inconsistent
                    return False
            elif file1.exists() != file2.exists():
                # One exists but not the other
                return False

        return True

    def _extract_all_text(self, element) -> str:
        """Extract all text content from an XML element."""
        text_parts = []

        if element.text:
            text_parts.append(element.text.strip())

        for child in element:
            text_parts.append(self._extract_all_text(child))

        return "".join(text_parts)

    def _compare_all_xml_files(self, dir1: Path, dir2: Path) -> Dict:
        """Compare all XML files in both directories."""
        comparisons = {}

        # Get all XML files from both directories
        xml_files = set()
        for root, dirs, files in os.walk(dir1):
            for file in files:
                if file.endswith('.xml') or file.endswith('.rels'):
                    rel_path = Path(root).relative_to(dir1) / file
                    xml_files.add(str(rel_path))

        for root, dirs, files in os.walk(dir2):
            for file in files:
                if file.endswith('.xml') or file.endswith('.rels'):
                    rel_path = Path(root).relative_to(dir2) / file
                    xml_files.add(str(rel_path))

        # Compare each XML file
        for xml_file in sorted(xml_files):
            file1 = dir1 / xml_file
            file2 = dir2 / xml_file
            comparisons[xml_file] = self._compare_xml_file(file1, file2)

        # For full comparison, also compare paragraph styles distribution
        doc1 = dir1 / "word/document.xml"
        doc2 = dir2 / "word/document.xml"
        if doc1.exists() and doc2.exists():
            comparisons["word/document.xml (æ®µè½æ ·å¼åˆ†å¸ƒ)"] = self._compare_paragraph_styles(doc1, doc2)

        return comparisons

    def _compare_format_files(self, dir1: Path, dir2: Path) -> Dict:
        """Compare only format-related XML files."""
        format_files = [
            "[Content_Types].xml",  # Content type definitions (critical!)
            "word/styles.xml",
            "word/numbering.xml",
            "word/settings.xml",
            "word/fontTable.xml",
            "word/footnotes.xml",   # Footnotes formatting
            "word/endnotes.xml",     # Endnotes formatting
        ]

        comparisons = {}
        for format_file in format_files:
            file1 = dir1 / format_file
            file2 = dir2 / format_file
            # Only add to comparisons if at least one file exists
            if file1.exists() or file2.exists():
                comparisons[format_file] = self._compare_xml_file(file1, file2)

        # Also compare document.xml structure (only sections, not paragraph styles)
        # Note: We don't compare paragraph styles because documents may have different content
        doc1 = dir1 / "word/document.xml"
        doc2 = dir2 / "word/document.xml"
        comparisons["word/document.xml (ä»…ç« èŠ‚)"] = self._compare_document_sections(doc1, doc2)

        # Note: We don't compare paragraph styles distribution in format-only comparison
        # because different documents will naturally have different content.
        # Paragraph styles distribution is only compared when full_compare=True.

        return comparisons

    def _merge_runs_in_tree(self, root) -> None:
        """
        Merge adjacent runs with identical formatting in the entire tree.

        This is done before normalization to eliminate run boundary differences
        that don't affect visual appearance. Two runs are merged if they have
        identical rPr (run properties) or both have no rPr.

        Args:
            root: XML root element to process
        """
        w_ns = {"w": "http://schemas.openxmlformats.org/wordprocessingml/2006/main"}

        # Process each paragraph
        for para in root.findall(".//w:p", namespaces=w_ns):
            runs = para.findall("w:r", namespaces=w_ns)
            if len(runs) < 2:
                continue

            i = 0
            while i < len(runs) - 1:
                current_run = runs[i]
                next_run = runs[i + 1]

                # Check if both runs can be merged
                if self._can_merge_runs_for_comparison(current_run, next_run, w_ns):
                    # Merge next_run into current_run
                    self._merge_run_text_for_comparison(current_run, next_run, w_ns)

                    # Remove next_run from paragraph
                    para.remove(next_run)

                    # Update runs list
                    runs = para.findall("w:r", namespaces=w_ns)
                    # Don't increment i - check if we can merge with the new next run
                else:
                    i += 1

    def _can_merge_runs_for_comparison(self, run1, run2, w_ns: dict) -> bool:
        """
        Check if two runs can be merged for comparison purposes.

        Two runs can be merged if they have the same formatting (both have
        identical rPr or both have no rPr).

        Args:
            run1: First run element
            run2: Second run element
            w_ns: Word namespace dictionary

        Returns:
            True if runs can be merged, False otherwise
        """
        # Get rPr elements
        rpr1 = run1.find("w:rPr", namespaces=w_ns)
        rpr2 = run2.find("w:rPr", namespaces=w_ns)

        # If both have no rPr, they can be merged
        if rpr1 is None and rpr2 is None:
            return True

        # If both have rPr, check if they're identical
        if rpr1 is not None and rpr2 is not None:
            # Compare rPr elements as strings
            str1 = etree.tostring(rpr1, method='c14n')
            str2 = etree.tostring(rpr2, method='c14n')
            return str1 == str2

        # One has rPr, one doesn't - can't merge
        return False

    def _merge_run_text_for_comparison(self, target_run, source_run, w_ns: dict) -> None:
        """
        Merge text from source_run into target_run.

        Concatenates all w:t elements from source_run into target_run.

        Args:
            target_run: Run to merge into (will be kept)
            source_run: Run to merge from (will be removed)
            w_ns: Word namespace dictionary
        """
        # Find all text elements in both runs
        target_texts = target_run.findall("w:t", namespaces=w_ns)
        source_texts = source_run.findall("w:t", namespaces=w_ns)

        # Preserve non-text elements (like tab, br, etc.) from source_run
        # These are elements that are not w:t and not in IGNORE_ELEMENTS
        source_non_text_children = []
        for child in source_run:
            if child.tag != f"{{{w_ns['w']}}}t" and child.tag not in self.IGNORE_ELEMENTS:
                source_non_text_children.append(child)

        if not target_texts:
            # Target run has no text, just move source texts and non-text elements
            for text_elem in source_texts:
                target_run.append(text_elem)
            for elem in source_non_text_children:
                target_run.append(elem)
        elif not source_texts:
            # Source run has no text, just move non-text elements
            for elem in source_non_text_children:
                target_run.append(elem)
            return
        else:
            # Both have text - concatenate the last target text with first source text
            last_target = target_texts[-1]
            first_source = source_texts[0]

            if last_target.text and first_source.text:
                last_target.text = last_target.text + first_source.text
            elif first_source.text:
                last_target.text = first_source.text

            # Move remaining source texts
            for text_elem in source_texts[1:]:
                target_run.append(text_elem)

            # Move non-text elements from source_run
            for elem in source_non_text_children:
                target_run.append(elem)

    def _compare_xml_file(self, file1: Path, file2: Path) -> Dict:
        """
        Compare two XML files.

        Args:
            file1: Path to first XML file
            file2: Path to second XML file

        Returns:
            Dictionary with comparison results
        """
        if not file1.exists() and not file2.exists():
            return {
                "identical": True,
                "reason": "ä¸¤ä¸ªæ–‡ä»¶éƒ½ä¸å­˜åœ¨",
            }

        if not file1.exists():
            return {
                "identical": False,
                "reason": f"æ–‡ä»¶ä»…å­˜åœ¨äºæ–‡æ¡£2ä¸­: {file2.name}",
            }

        if not file2.exists():
            return {
                "identical": False,
                "reason": f"æ–‡ä»¶ä»…å­˜åœ¨äºæ–‡æ¡£1ä¸­: {file1.name}",
            }

        try:
            # Parse and normalize both files
            tree1 = etree.parse(file1)
            tree2 = etree.parse(file2)

            # Pre-process: merge adjacent runs with identical formatting
            # This eliminates run boundary differences when formatting is the same
            self._merge_runs_in_tree(tree1.getroot())
            self._merge_runs_in_tree(tree2.getroot())

            root1_normalized = self._normalize_xml(tree1.getroot())
            root2_normalized = self._normalize_xml(tree2.getroot())

            # Convert to canonical strings for comparison
            xml1_str = etree.tostring(
                root1_normalized,
                method='c14n',
                exclusive=True
            ).decode('utf-8')

            xml2_str = etree.tostring(
                root2_normalized,
                method='c14n',
                exclusive=True
            ).decode('utf-8')

            # Compare
            if xml1_str == xml2_str:
                return {
                    "identical": True,
                    "reason": "æ–‡ä»¶å®Œå…¨ç›¸åŒï¼ˆå·²æ ‡å‡†åŒ–ï¼‰",
                }
            else:
                # Calculate similarity
                similarity = SequenceMatcher(None, xml1_str, xml2_str).ratio()

                return {
                    "identical": False,
                    "reason": "æ–‡ä»¶å­˜åœ¨å·®å¼‚ï¼ˆå·²æ ‡å‡†åŒ–ï¼‰",
                    "similarity": similarity,
                }

        except Exception as e:
            return {
                "identical": False,
                "reason": f"æ¯”è¾ƒæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}",
            }

    def _normalize_xml(self, element) -> etree.Element:
        """
        Normalize an XML element by removing ignored attributes and elements.

        Args:
            element: XML element to normalize

        Returns:
            Normalized XML element
        """
        # Skip ignored elements (like rPr - run properties)
        if element.tag in self.IGNORE_ELEMENTS:
            # Return a placeholder to maintain structure but without content
            return None

        # Create a copy to avoid modifying the original
        element_copy = etree.Element(element.tag, nsmap=element.nsmap)

        # Copy attributes (excluding ignored ones)
        for attr, value in element.attrib.items():
            if attr not in self.IGNORE_ATTRS:
                element_copy.set(attr, value)

        # Copy children recursively, skipping ignored elements
        for child in element:
            normalized_child = self._normalize_xml(child)
            # Only add non-None children (None means it was an ignored element)
            if normalized_child is not None:
                element_copy.append(normalized_child)

        # Copy text
        if element.text:
            element_copy.text = element.text

        if element.tail:
            element_copy.tail = element.tail

        return element_copy

    def _compare_document_structure(self, file1: Path, file2: Path) -> Dict:
        """
        Compare document structure (sections, paragraphs, styles) without comparing text content.

        This checks if:
        - Sections are preserved
        - Paragraph styles are preserved
        - Headings hierarchy is preserved
        But ignores the actual text content
        """
        if not file1.exists() and not file2.exists():
            return {
                "identical": True,
                "reason": "ä¸¤ä¸ªdocument.xmlæ–‡ä»¶éƒ½ä¸å­˜åœ¨",
            }

        if not file1.exists() or not file2.exists():
            return {
                "identical": False,
                "reason": "ç¼ºå°‘ä¸€ä¸ªdocument.xmlæ–‡ä»¶",
                "similarity": 0.0,
            }

        try:
            tree1 = etree.parse(file1)
            tree2 = etree.parse(file2)

            # Extract structural elements
            structure1 = self._extract_document_structure(tree1.getroot())
            structure2 = self._extract_document_structure(tree2.getroot())

            # Compare structures
            if structure1 == structure2:
                return {
                    "identical": True,
                    "reason": "æ–‡æ¡£ç»“æ„å®Œå…¨ç›¸åŒ",
                }
            else:
                # Calculate similarity based on structure matching
                similarity = self._calculate_structure_similarity(structure1, structure2)
                return {
                    "identical": False,
                    "reason": "æ–‡æ¡£ç»“æ„å­˜åœ¨å·®å¼‚",
                    "similarity": similarity,
                }

        except Exception as e:
            return {
                "identical": False,
                "reason": f"æ¯”è¾ƒæ–‡æ¡£ç»“æ„æ—¶å‡ºé”™: {str(e)}",
                "similarity": 0.0,
            }

    def _compare_document_sections(self, file1: Path, file2: Path) -> Dict:
        """
        Compare only document sections (page layout, headers/footers, margins).

        This does NOT compare paragraph styles because documents may have different content.
        We only verify that sections (which define page formatting) are preserved from template.
        """
        if not file1.exists() and not file2.exists():
            return {
                "identical": True,
                "reason": "ä¸¤ä¸ªdocument.xmlæ–‡ä»¶éƒ½ä¸å­˜åœ¨",
            }

        if not file1.exists() or not file2.exists():
            return {
                "identical": False,
                "reason": "ç¼ºå°‘ä¸€ä¸ªdocument.xmlæ–‡ä»¶",
                "similarity": 0.0,
            }

        try:
            tree1 = etree.parse(file1)
            tree2 = etree.parse(file2)

            w_ns = {"w": "http://schemas.openxmlformats.org/wordprocessingml/2006/main"}

            # Extract sections only
            sections1 = tree1.getroot().xpath("//w:sectPr", namespaces=w_ns)
            sections2 = tree2.getroot().xpath("//w:sectPr", namespaces=w_ns)

            # Compare section count and content
            if len(sections1) == len(sections2):
                if len(sections1) == 0:
                    return {
                        "identical": True,
                        "reason": "ä¸¤ä¸ªæ–‡æ¡£éƒ½æ²¡æœ‰ç« èŠ‚å®šä¹‰",
                    }
                else:
                    # Normalize sections by removing rsid attributes before comparison
                    def normalize_section(section_elem):
                        """Remove non-deterministic rsid attributes from section"""
                        # Create a copy to avoid modifying original
                        section_copy = etree.fromstring(etree.tostring(section_elem))
                        # Remove rsid attributes
                        for attr in list(section_copy.attrib.keys()):
                            if 'rsid' in attr.lower():
                                del section_copy.attrib[attr]
                        return section_copy

                    norm_sections1 = [normalize_section(s) for s in sections1]
                    norm_sections2 = [normalize_section(s) for s in sections2]

                    # Compare normalized sections
                    sections1_str = [etree.tostring(s, method='c14n') for s in norm_sections1]
                    sections2_str = [etree.tostring(s, method='c14n') for s in norm_sections2]

                    if sections1_str == sections2_str:
                        return {
                            "identical": True,
                            "reason": "ç« èŠ‚å®šä¹‰å®Œå…¨ä¸€è‡´",
                        }
                    else:
                        return {
                            "identical": False,
                            "reason": "ç« èŠ‚æ•°é‡ç›¸åŒä½†å®šä¹‰ä¸åŒ",
                            "similarity": 0.8,
                        }
            else:
                # Different number of sections
                return {
                    "identical": False,
                    "reason": f"ç« èŠ‚æ•°é‡ä¸åŒ ({len(sections1)} vs {len(sections2)})",
                    "similarity": 0.5,
                }

        except Exception as e:
            return {
                "identical": False,
                "reason": f"æ¯”è¾ƒç« èŠ‚æ—¶å‡ºé”™: {str(e)}",
                "similarity": 0.0,
            }

    def _compare_paragraph_styles(self, file1: Path, file2: Path) -> Dict:
        """
        Compare paragraph styles distribution in document.xml.

        This checks if the same styles are used with similar frequency,
        which indicates format consistency even if content differs.

        NOTE: Only counts paragraph styles (type="paragraph"), not character styles.
        Character styles used in paragraphs are filtered out to avoid false comparisons.
        """
        if not file1.exists() and not file2.exists():
            return {
                "identical": True,
                "reason": "ä¸¤ä¸ªdocument.xmlæ–‡ä»¶éƒ½ä¸å­˜åœ¨",
            }

        if not file1.exists() or not file2.exists():
            return {
                "identical": False,
                "reason": "ç¼ºå°‘ä¸€ä¸ªdocument.xmlæ–‡ä»¶",
                "similarity": 0.0,
            }

        try:
            tree1 = etree.parse(file1)
            tree2 = etree.parse(file2)

            w_ns = {"w": "http://schemas.openxmlformats.org/wordprocessingml/2006/main"}

            # Helper to get styles.xml from document's directory
            def get_styles_map(doc_xml_path):
                """Extract paragraph style IDs from styles.xml"""
                styles_xml = doc_xml_path.parent.parent / "styles.xml"
                if not styles_xml.exists():
                    return {}

                try:
                    styles_tree = etree.parse(styles_xml)
                    paragraph_style_ids = set()
                    for style in styles_tree.getroot().xpath("//w:style[@w:type='paragraph']", namespaces=w_ns):
                        style_id = style.get(f"{{{w_ns['w']}}}styleId")
                        if style_id:
                            paragraph_style_ids.add(style_id)
                    return paragraph_style_ids
                except Exception:
                    return {}

            # Get paragraph style IDs for both documents
            para_style_ids_1 = get_styles_map(file1)
            para_style_ids_2 = get_styles_map(file2)

            # Count paragraph styles in each document
            def count_styles(tree, paragraph_style_ids):
                root = tree.getroot()
                styles_count = {}
                for p in root.xpath("//w:p", namespaces=w_ns):
                    p_style = p.find("w:pPr/w:pStyle", namespaces=w_ns)
                    if p_style is not None:
                        style_id = p_style.get(f"{{{w_ns['w']}}}val")
                        if style_id:
                            # IMPORTANT: Only count if it's a paragraph style
                            # Filter out character styles (like 'afc', '30') that are incorrectly used
                            if style_id in paragraph_style_ids:
                                styles_count[style_id] = styles_count.get(style_id, 0) + 1
                            else:
                                # Character style used in paragraph - count as "æ— æ•ˆæ ·å¼"
                                styles_count["(æ— æ•ˆå­—ç¬¦æ ·å¼)"] = styles_count.get("(æ— æ•ˆå­—ç¬¦æ ·å¼)", 0) + 1
                    else:
                        # Paragraph without explicit style
                        styles_count["(æ— æ ·å¼)"] = styles_count.get("(æ— æ ·å¼)", 0) + 1
                return styles_count

            styles1 = count_styles(tree1, para_style_ids_1)
            styles2 = count_styles(tree2, para_style_ids_2)

            # Calculate similarity based on style distribution
            all_styles = set(styles1.keys()) | set(styles2.keys())

            if not all_styles:
                return {
                    "identical": True,
                    "reason": "ä¸¤ä¸ªæ–‡æ¡£éƒ½æ²¡æœ‰æ®µè½",
                }

            # Calculate total paragraphs
            total1 = sum(styles1.values())
            total2 = sum(styles2.values())

            # Calculate similarity using weighted comparison
            similarity = 0.0
            for style in all_styles:
                count1 = styles1.get(style, 0)
                count2 = styles2.get(style, 0)

                # Normalize by total
                freq1 = count1 / total1 if total1 > 0 else 0
                freq2 = count2 / total2 if total2 > 0 else 0

                # Use cosine similarity-like approach
                # If both documents use this style, reward; if only one does, penalize
                if count1 > 0 and count2 > 0:
                    # Both have this style
                    weight = min(freq1, freq2) / max(freq1, freq2)
                elif count1 == 0 and count2 == 0:
                    weight = 1.0
                else:
                    # Only one has this style
                    weight = 0.0

                # Weight by importance (more common styles are more important)
                importance = (count1 + count2) / (total1 + total2)
                similarity += weight * importance

            if similarity >= 0.99:
                return {
                    "identical": True,
                    "reason": "æ®µè½æ ·å¼åˆ†å¸ƒå®Œå…¨ä¸€è‡´",
                }
            else:
                return {
                    "identical": False,
                    "reason": "æ®µè½æ ·å¼åˆ†å¸ƒä¸åŒ",
                    "similarity": similarity,
                }

        except Exception as e:
            return {
                "identical": False,
                "reason": f"æ¯”è¾ƒæ®µè½æ ·å¼æ—¶å‡ºé”™: {str(e)}",
                "similarity": 0.0,
            }

    def _extract_document_structure(self, root) -> dict:
        """Extract structural information from document.xml."""
        structure = {
            "sections": [],
            "paragraph_styles": [],
        }

        # Namespace for Word documents
        w_ns = {"w": "http://schemas.openxmlformats.org/wordprocessingml/2006/main"}

        # Extract sections (w:sectPr)
        for sect in root.xpath("//w:sectPr", namespaces=w_ns):
            structure["sections"].append(etree.tostring(sect, method='c14n'))

        # Extract paragraph styles (w:pStyle)
        for p_style in root.xpath("//w:p/w:pPr/w:pStyle", namespaces=w_ns):
            val = p_style.get("{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val", "")
            if val:
                structure["paragraph_styles"].append(val)

        return structure

    def _calculate_structure_similarity(self, struct1: dict, struct2: dict) -> float:
        """Calculate similarity between two document structures."""
        # Compare section count
        sections_match = len(struct1["sections"]) == len(struct2["sections"])

        # Compare paragraph styles
        styles1 = set(struct1["paragraph_styles"])
        styles2 = set(struct2["paragraph_styles"])

        if not styles1 and not styles2:
            style_similarity = 1.0
        elif not styles1 or not styles2:
            style_similarity = 0.0
        else:
            # Jaccard similarity for styles
            intersection = len(styles1 & styles2)
            union = len(styles1 | styles2)
            style_similarity = intersection / union if union > 0 else 0.0

        # Weight sections and styles equally
        section_score = 1.0 if sections_match else 0.5
        overall_similarity = (section_score + style_similarity) / 2

        return overall_similarity

    def _calculate_similarity(self, file_comparisons: Dict) -> float:
        """
        Calculate overall similarity from file comparisons.

        Args:
            file_comparisons: Dictionary of file comparison results

        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not file_comparisons:
            return 0.0

        total_similarity = 0.0
        count = 0

        for file_path, comparison in file_comparisons.items():
            if comparison.get("identical"):
                total_similarity += 1.0
            elif "similarity" in comparison:
                total_similarity += comparison["similarity"]
            count += 1

        return total_similarity / count if count > 0 else 0.0

    def generate_report(self, comparison_result: Dict, doc1_name: str, doc2_name: str) -> str:
        """
        Generate a human-readable comparison report.

        Args:
            comparison_result: Result from compare_documents()
            doc1_name: Name of first document
            doc2_name: Name of second document

        Returns:
            Formatted report string
        """
        lines = []
        lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        lines.append("ğŸ“Š æ ¼å¼å¯¹æ¯”æŠ¥å‘Š")
        lines.append(f"æ ¼å¼åŸºå‡†æ–‡æ¡£: {doc1_name}")
        lines.append(f"å¾…éªŒè¯æ–‡æ¡£: {doc2_name}")
        lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        lines.append("")

        # æ·»åŠ ç™½åå•è¿‡æ»¤è¯´æ˜
        lines.append("âš™ï¸  ç›¸ä¼¼åº¦è®¡ç®—è¯´æ˜:")
        lines.append("  ä»¥ä¸‹éç¡®å®šæ€§å±æ€§å’Œå…ƒç´ å·²è¢«ç™½åå•è¿‡æ»¤ï¼Œä¸è®¡å…¥ç›¸ä¼¼åº¦ç»Ÿè®¡:")
        ignored_attrs_desc = [
            "  â€¢ rsidç³»åˆ—å±æ€§ (ä¿®è®¢æ ‡è¯†ç¬¦ - Wordä¸´æ—¶ç¼–è¾‘æ ‡è®°)",
            "  â€¢ paraId, textId (æ®µè½IDå’Œæ–‡æœ¬ID - Wordè‡ªåŠ¨ç”Ÿæˆ)",
            "  â€¢ rPrå…ƒç´  (æ–‡æœ¬è¿è¡Œå±æ€§ - å­—ä½“ã€é¢œè‰²ã€åŠ ç²—ç­‰ç›´æ¥æ ¼å¼)",
            "  â€¢ lastModifiedBy, modified, created, revision (å…ƒæ•°æ®æ—¶é—´æˆ³)",
            "  â„¹ï¸  è¿™äº›å±æ€§å’Œå…ƒç´ ä¸å½±å“æ–‡æ¡£çš„è¯­ä¹‰ç»“æ„ï¼Œä¸è®¡å…¥ç›¸ä¼¼åº¦ç»Ÿè®¡"
        ]
        lines.extend(ignored_attrs_desc)
        lines.append("")

        # Content consistency status
        if not comparison_result.get("content_consistent"):
            lines.append("âš ï¸  å†…å®¹æ£€æŸ¥: æ–‡æ¡£å†…å®¹ä¸ä¸€è‡´")
            lines.append("  â„¹ï¸  æ³¨æ„: æ ¼å¼ç›¸ä¼¼åº¦ä»ç„¶å¯ä»¥ç”¨äºè¯„ä¼°æ ¼å¼è¿˜åŸæ•ˆæœ")
            lines.append("")
        else:
            lines.append("âœ… å†…å®¹æ£€æŸ¥: æ–‡æ¡£å†…å®¹ä¸€è‡´")
            lines.append("  â„¹ï¸  å¯è¿›è¡Œå®Œæ•´çš„æ ¼å¼éªŒè¯")
            lines.append("")

        lines.append("ğŸ“‹ XMLæ–‡ä»¶å¯¹æ¯”:")

        file_comparisons = comparison_result.get("file_comparisons", {})

        for file_path, comparison in sorted(file_comparisons.items()):
            if comparison.get("identical"):
                lines.append(f"  âœ“ {file_path}: å®Œå…¨ä¸€è‡´")
            else:
                reason = comparison.get("reason", "Unknown reason")
                similarity = comparison.get("similarity", 0.0)
                lines.append(f"  â€¢ {file_path}: ç›¸ä¼¼åº¦ {similarity:.1%}")

        lines.append("")
        overall_similarity = comparison_result.get("overall_similarity", 0.0)
        lines.append(f"ğŸ“ˆ æ•´ä½“æ ¼å¼ç›¸ä¼¼åº¦: {overall_similarity:.1%}")
        lines.append("")

        if overall_similarity >= 1.0:
            lines.append("âœ… ç»“è®º: æ ¼å¼è¿˜åŸå®Œå…¨æˆåŠŸï¼")
        elif overall_similarity >= 0.9:
            lines.append("âš ï¸  ç»“è®º: æ ¼å¼è¿˜åŸåŸºæœ¬æˆåŠŸï¼Œæœ‰è½»å¾®å·®å¼‚ã€‚")
        elif overall_similarity >= 0.7:
            lines.append("âš ï¸  ç»“è®º: æ ¼å¼è¿˜åŸéƒ¨åˆ†æˆåŠŸï¼Œå»ºè®®æ£€æŸ¥å·®å¼‚ã€‚")
        else:
            lines.append("âŒ ç»“è®º: æ ¼å¼è¿˜åŸå­˜åœ¨é—®é¢˜ï¼Œéœ€è¦äººå·¥æ£€æŸ¥ã€‚")

        lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

        return "\n".join(lines)
